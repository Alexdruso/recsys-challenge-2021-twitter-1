{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c316be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set({\"temporary-directory\": \"/home/ubuntu/data/dask_tmp\"})\n",
    "dask.config.set({'distributed.worker.memory.target': 0.85})\n",
    "dask.config.set({'distributed.worker.memory.spill': 0.90})\n",
    "dask.config.set({'distributed.worker.memory.pause': 0.93})\n",
    "dask.config.set({'distributed.worker.memory.terminate': 0.96})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_cluster(n_workers, threads_per_worker, memory_limit, processes):\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers, threads_per_worker=threads_per_worker, memory_limit=memory_limit, processes=processes\n",
    "    )\n",
    "    client = Client(cluster)  # use default n_threads and mem\n",
    "    print(client)\n",
    "    print(client.cluster)\n",
    "    return client\n",
    "\n",
    "c = start_cluster(n_workers=8, threads_per_worker=1, memory_limit=\"24GB\", processes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Preprocessed/Valid/FeatureExtraction/All_feature_dataset/Valid_with_TE\"\n",
    "schema = pa.Schema.from_pandas(pd.read_parquet(path + \"/part.0.parquet\", engine='pyarrow'))\n",
    "df = dd.read_parquet(path, engine='pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738463fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~df['is_from_official_val']]\n",
    "val_df = df[df['is_from_official_val']]\n",
    "\n",
    "val1_df, val2_df = val_df.random_split([2/3, 1/3], random_state=123)\n",
    "\n",
    "train_df_time = train_df[train_df['tweet_timestamp'] > 1.614011e+09]\n",
    "train_df_notime = train_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_noval_notime= train_df_notime\n",
    "final_train_noval_time = train_df_time\n",
    "final_train_val_notime = dd.concat([train_df_notime, val1_df], axis=0)\n",
    "final_train_val_time = dd.concat([train_df_time, val1_df], axis=0)\n",
    "\n",
    "\n",
    "test_df = val2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_noval_notime = final_train_noval_notime.repartition(partition_size=\"200MB\")\n",
    "final_train_noval_notime.to_parquet(\"new/final_train_noval_notime\", engine='pyarrow', schema=schema, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_noval_time = final_train_noval_time.repartition(partition_size=\"200MB\")\n",
    "final_train_noval_time.to_parquet(\"new/final_train_noval_time\", engine='pyarrow', schema=schema, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_val_notime = final_train_val_notime.repartition(partition_size=\"200MB\")\n",
    "final_train_val_notime.to_parquet(\"new/final_train_val_notime\", engine='pyarrow', schema=schema, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25264d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_val_time = final_train_val_time.repartition(partition_size=\"200MB\")\n",
    "final_train_val_time.to_parquet(\"new/final_train_val_time\", engine='pyarrow', schema=schema, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc28799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.repartition(partition_size=\"200MB\")\n",
    "test_df.to_parquet(\"new/test\", engine='pyarrow', schema=schema, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d2e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4a047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b281a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479c29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (recsys-challenge-2021-twitter)",
   "language": "python",
   "name": "pycharm-cc02c472"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}